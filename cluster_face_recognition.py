"""
–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –≤–µ—Ä—Å–∏—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º face_recognition (dlib-based).
–ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è, —á–µ–º insightface, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–∞—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install face-recognition==1.3.0
    pip install face-recognition-models==0.3.0
    pip install dlib==19.24.6
"""
from __future__ import annotations
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Optional, Tuple

import numpy as np
import cv2
from PIL import Image
from collections import defaultdict, deque

# Faiss –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–∏ —Å–±–æ—Ä–∫–µ ‚Äî –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç.
try:
    import faiss  # type: ignore
except Exception as e:  # pragma: no cover
    faiss = None

try:
    import face_recognition
except Exception as e:  # pragma: no cover
    face_recognition = None

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"}
ProgressCB = Optional[Callable[[str, int], None]]

# ------------------------
# –£—Ç–∏–ª–∏—Ç—ã –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞
# ------------------------

def is_image(path: Path) -> bool:
    return path.suffix.lower() in IMG_EXTS


def imread_safe(path: Path) -> Optional[np.ndarray]:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è face_recognition."""
    try:
        # face_recognition —Ä–∞–±–æ—Ç–∞–µ—Ç —Å PIL –∏–ª–∏ numpy –º–∞—Å—Å–∏–≤–∞–º–∏
        image = face_recognition.load_image_file(str(path))
        return image
    except Exception:
        return None

# ------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ face_recognition
# ------------------------
@dataclass
class FaceRecConfig:
    model: str = "cnn"  # "hog" –∏–ª–∏ "cnn" (cnn —Ç–æ—á–Ω–µ–µ –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
    tolerance: float = 0.5  # –ø–æ—Ä–æ–≥ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–∏—Ü (–º–µ–Ω—å—à–µ = —Å—Ç—Ä–æ–∂–µ)


class FaceRecEmbedder:
    def __init__(self, config: FaceRecConfig = FaceRecConfig()):
        if face_recognition is None:
            raise ImportError("face_recognition –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç face_recognition.")
        self.config = config

    def extract(self, img_rgb: np.ndarray) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–∏—Ü: [{encoding, location}]."""
        # face_recognition.load_image_file —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç RGB
        face_locations = face_recognition.face_locations(img_rgb, model=self.config.model)
        face_encodings = face_recognition.face_encodings(img_rgb, face_locations)

        results = []
        for location, encoding in zip(face_locations, face_encodings):
            results.append({
                "encoding": encoding,  # 128-dimensional encoding
                "location": location,  # (top, right, bottom, left)
            })
        return results

# ------------------------
# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Faiss (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥)
# ------------------------
@dataclass
class ClusterParams:
    sim_threshold: float = 0.45   # –Ω–∏–∂–µ –ø–æ—Ä–æ–≥ –¥–ª—è face_recognition (—Å—Ç—Ä–æ–∂–µ)
    min_cluster_size: int = 2     # —Å—Ä–µ–∑–∞–µ–º –º–µ–ª–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–∞–∫ –æ–¥–∏–Ω–æ—á–∫–∏
    use_faiss: bool = True        # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Faiss –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥


def _build_similarity_graph_faiss(embeddings: np.ndarray, params: ClusterParams) -> List[List[int]]:
    if faiss is None:
        raise ImportError("faiss –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ faiss-gpu –∏–ª–∏ faiss-cpu.")
    if embeddings.dtype != np.float32:
        embeddings = embeddings.astype(np.float32)

    # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É–∂–µ L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è cosine=dot
    d = embeddings.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embeddings)

    # range_search: –≤–µ—Ä–Ω—ë—Ç –ø–∞—Ä—ã (i,j) —Å sim >= threshold
    lims, D, I = index.range_search(embeddings, params.sim_threshold)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ —Å–º–µ–∂–Ω–æ—Å—Ç–∏
    n = embeddings.shape[0]
    adj: List[List[int]] = [[] for _ in range(n)]
    for i in range(n):
        beg, end = lims[i], lims[i + 1]
        pairs = sorted(zip(I[beg:end], D[beg:end]), key=lambda t: -t[1])
        for j, sim in pairs:
            if j == i or j < 0:
                continue
            adj[i].append(int(j))
    return adj


def _simple_clustering(embeddings: np.ndarray, params: ClusterParams) -> np.ndarray:
    """–ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –±–µ–∑ Faiss"""
    n = len(embeddings)
    labels = -np.ones(n, dtype=np.int32)
    cid = 0

    for i in range(n):
        if labels[i] != -1:
            continue

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ –ª–∏—Ü–∞ –¥–ª—è —ç—Ç–æ–≥–æ –ª–∏—Ü–∞
        similar = [i]
        for j in range(n):
            if i == j or labels[j] != -1:
                continue
            # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å
            sim = np.dot(embeddings[i], embeddings[j])
            if sim >= params.sim_threshold:
                similar.append(j)

        if len(similar) >= params.min_cluster_size:
            for idx in similar:
                labels[idx] = cid
            cid += 1

    return labels


def _connected_components(adj: List[List[int]]) -> np.ndarray:
    n = len(adj)
    labels = -np.ones(n, dtype=np.int32)
    cid = 0
    for i in range(n):
        if labels[i] != -1:
            continue
        q = deque([i])
        labels[i] = cid
        while q:
            u = q.popleft()
            for v in adj[u]:
                if labels[v] == -1:
                    labels[v] = cid
                    q.append(v)
        cid += 1
    return labels


def cluster_embeddings(embeddings: np.ndarray, params: ClusterParams) -> np.ndarray:
    if embeddings.size == 0:
        return np.array([], dtype=np.int32)

    if params.use_faiss and faiss is not None:
        adj = _build_similarity_graph_faiss(embeddings, params)
        labels = _connected_components(adj)
    else:
        labels = _simple_clustering(embeddings, params)

    # –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –º–µ–ª–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã
    sizes = defaultdict(int)
    for lb in labels:
        sizes[int(lb)] += 1

    for i, lb in enumerate(labels):
        if lb != -1 and sizes[int(lb)] < params.min_cluster_size:
            labels[i] = -1

    # –°–∂–∏–º–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    if np.any(labels != -1):
        uniq = sorted(x for x in set(labels.tolist()) if x != -1)
        remap = {old: i for i, old in enumerate(uniq)}
        out = labels.copy()
        for i, lb in enumerate(labels):
            if lb == -1:
                out[i] = -1
            else:
                out[i] = remap[int(lb)]
        return out
    return labels

# ------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω
# ------------------------

def build_plan_face_recognition(
    input_dir: Path,
    progress_callback: ProgressCB = None,
    sim_threshold: float = 0.6,
    min_cluster_size: int = 2,
    model: str = "hog",
) -> Dict:
    """–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ª–∏—Ü —Å face_recognition + Faiss.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π build_plan_pro
    """
    t0 = time.time()
    input_dir = Path(input_dir)
    if progress_callback:
        progress_callback(f"üöÄ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {input_dir}", 2)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–µ—Ä–∞
    emb = FaceRecEmbedder(FaceRecConfig(model=model, tolerance=sim_threshold))

    # –°–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    all_images = [p for p in input_dir.rglob("*") if p.is_file() and is_image(p)]
    if progress_callback:
        progress_callback(f"üìÇ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}", 5)

    owners: List[Path] = []
    all_embeddings: List[np.ndarray] = []
    img_face_count: Dict[Path, int] = {}
    unreadable: List[Path] = []
    no_faces: List[Path] = []

    total = len(all_images)
    for i, img_path in enumerate(all_images):
        if progress_callback and (i % 5 == 0):  # —Ä–µ–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            percent = 5 + int((i + 1) / max(1, total) * 60)
            progress_callback(f"üì∑ –ê–Ω–∞–ª–∏–∑ {i+1}/{total}", percent)

        img = imread_safe(img_path)
        if img is None:
            unreadable.append(img_path)
            continue

        faces = emb.extract(img)
        if not faces:
            no_faces.append(img_path)
            continue

        img_face_count[img_path] = len(faces)
        for face in faces:
            all_embeddings.append(face["encoding"])
            owners.append(img_path)

    if not all_embeddings:
        return {
            "clusters": {},
            "plan": [],
            "unreadable": [str(p) for p in unreadable],
            "no_faces": [str(p) for p in no_faces],
        }

    X = np.vstack(all_embeddings).astype(np.float32)

    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    if progress_callback:
        progress_callback("üîó –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏", 70)
    labels = cluster_embeddings(
        X,
        ClusterParams(sim_threshold=sim_threshold, min_cluster_size=min_cluster_size),
    )

    if progress_callback:
        progress_callback(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(set(labels.tolist()) - {-1})}", 85)

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞–ø–æ–≤
    cluster_map: Dict[int, set[Path]] = defaultdict(set)
    cluster_by_img: Dict[Path, set[int]] = defaultdict(set)

    for lb, path in zip(labels, owners):
        if lb == -1:
            continue
        cluster_map[int(lb)].add(path)
        cluster_by_img[path].add(int(lb))

    # –ü–ª–∞–Ω –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π
    plan: List[Dict] = []
    for path in all_images:
        cl = cluster_by_img.get(path)
        if not cl:
            continue
        plan.append({
            "path": str(path),
            "cluster": sorted(list(cl)),
            "faces": img_face_count.get(path, 0),
        })

    if progress_callback:
        dt = time.time() - t0
        progress_callback(f"‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {dt:.1f}—Å", 95)

    return {
        "clusters": {str(k): [str(p) for p in sorted(v)] for k, v in cluster_map.items()},
        "plan": plan,
        "unreadable": [str(p) for p in unreadable],
        "no_faces": [str(p) for p in no_faces],
    }


# ------------------------
# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–∞–ø–∫–∞–º (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π)
# ------------------------

EXCLUDED_COMMON_NAMES = ["–æ–±—â–∏–µ", "–æ–±—â–∞—è", "common", "shared", "–≤—Å–µ", "all", "mixed", "—Å–º–µ—à–∞–Ω–Ω—ã–µ"]


def distribute_to_folders(plan: dict, base_dir: Path, cluster_start: int = 1, progress_callback: ProgressCB = None, common_mode: bool = False) -> Tuple[int, int, int]:
    import shutil

    moved, copied = 0, 0
    moved_paths = set()

    used_clusters = sorted({c for item in plan.get("plan", []) for c in item["cluster"]})
    common_photo_clusters = set()
    if common_mode:
        for item in plan.get("plan", []):
            src = Path(item["path"])
            is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)
            if is_common_photo:
                common_photo_clusters.update(item["cluster"])

        used_clusters = sorted(set(used_clusters) | common_photo_clusters)

    # –í —Ä–µ–∂–∏–º–µ common_mode —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, –∏–Ω–∞—á–µ –ø–µ—Ä–µ–Ω—É–º–µ—Ä–æ–≤—ã–≤–∞–µ–º
    if common_mode:
        cluster_id_map = {old: old for old in used_clusters}  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–æ–º–µ—Ä–∞
    else:
        cluster_id_map = {old: cluster_start + idx for idx, old in enumerate(used_clusters)}

    plan_items = plan.get("plan", [])
    total_items = len(plan_items)
    if progress_callback:
        progress_callback(f"üîÑ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {total_items} —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞–ø–∫–∞–º...", 0)

    cluster_file_counts: Dict[int, int] = {}
    for item in plan_items:
        src = Path(item["path"])
        is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)
        if not is_common_photo:
            clusters = [cluster_id_map[c] for c in item["cluster"]]
            for cid in clusters:
                cluster_file_counts[cid] = cluster_file_counts.get(cid, 0) + 1

    for i, item in enumerate(plan_items):
        if progress_callback:
            percent = int((i + 1) / max(total_items, 1) * 100)
            progress_callback(f"üìÅ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: {percent}% ({i+1}/{total_items})", percent)

        src = Path(item["path"])
        clusters = [cluster_id_map[c] for c in item["cluster"]]
        if not src.exists():
            continue

        is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)

        if is_common_photo:
            print(f"üìå –û–±—â–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –æ—Å—Ç–∞–≤–ª–µ–Ω–∞: {src.name}")
            continue

        if len(clusters) == 1:
            parent_folder = src.parent
            dst = parent_folder / f"{clusters[0]}" / src.name
            dst.parent.mkdir(parents=True, exist_ok=True)
            if src.resolve() != dst.resolve():
                shutil.move(str(src), str(dst))
                moved += 1
                moved_paths.add(src.parent)
        else:
            parent_folder = src.parent
            for cid in clusters:
                dst = parent_folder / f"{cid}" / src.name
                dst.parent.mkdir(parents=True, exist_ok=True)
                if src.resolve() != dst.resolve():
                    shutil.copy2(str(src), str(dst))
                    copied += 1
            try:
                src.unlink()
            except Exception:
                pass

    # –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
    if progress_callback:
        progress_callback("üßπ –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫...", 95)

    parent_folders = set()
    for item in plan_items:
        src = Path(item["path"])
        if src.parent.exists():
            parent_folders.add(src.parent)

    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    for parent_folder in parent_folders:
        for cid in cluster_file_counts.keys():
            folder_path = parent_folder / str(cid)
            if folder_path.exists():
                real_count = 0
                for file_path in folder_path.iterdir():
                    if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']:
                        real_count += 1

                if real_count == 0:
                    try:
                        folder_path.rmdir()
                        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {folder_path}")
                    except Exception:
                        pass

    # –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∫–∞—Ç–∞–ª–æ–≥–æ–≤
    if progress_callback:
        progress_callback("üßπ –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫...", 100)
    for p in sorted(moved_paths, key=lambda x: len(str(x)), reverse=True):
        try:
            p.rmdir()
        except Exception:
            pass

    # –í —Ä–µ–∂–∏–º–µ –û–ë–©–ê–Ø —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ + 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
    if common_mode:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –ø–∞–ø–∫–µ (–Ω–µ –≤ –ø–∞–ø–∫–µ "–æ–±—â–∏–µ")
        parent_dir = base_dir.parent
        print(f"üìÅ –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {parent_dir}")

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (—Ç–µ–ø–µ—Ä—å —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –Ω–æ–º–µ—Ä–∞–º–∏)
        for cluster_id in used_clusters:
            empty_folder = parent_dir / str(cluster_id)
            empty_folder.mkdir(parents=True, exist_ok=True)
            print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞: {cluster_id} –≤ {parent_dir}")

        # –°–æ–∑–¥–∞–µ–º 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
        max_cluster_id = max(used_clusters) if used_clusters else 0
        for i in range(1, 3):  # –°–æ–∑–¥–∞–µ–º 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏
            extra_cluster_id = max_cluster_id + i
            extra_folder = parent_dir / str(extra_cluster_id)
            extra_folder.mkdir(parents=True, exist_ok=True)
            print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {extra_cluster_id} –≤ {parent_dir}")

    return moved, copied, cluster_start + len(used_clusters)


# ------------------------
# –ì—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
# ------------------------

def find_common_folders_recursive(group_dir: Path) -> List[Path]:
    common: List[Path] = []
    print(f"üîç –ò—â–µ–º –æ–±—â–∏–µ –ø–∞–ø–∫–∏ –≤: {group_dir}")
    for subdir in group_dir.rglob("*"):
        if subdir.is_dir():
            print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–ø–∫—É: {subdir.name}")
            if any(ex in subdir.name.lower() for ex in EXCLUDED_COMMON_NAMES):
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –æ–±—â–∞—è –ø–∞–ø–∫–∞: {subdir}")
                common.append(subdir)
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –æ–±—â–∏—Ö –ø–∞–ø–æ–∫: {len(common)}")
    return common


def process_common_folder_at_level(common_dir: Path, progress_callback: ProgressCB = None,
                                   sim_threshold: float = 0.6, min_cluster_size: int = 2,
                                   model: str = "hog") -> Tuple[int, int]:
    data = build_plan_face_recognition(common_dir, progress_callback=progress_callback,
                                     sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                                     model=model)
    moved, copied, _ = distribute_to_folders(data, common_dir, cluster_start=1, progress_callback=progress_callback, common_mode=True)
    return moved, copied


def process_group_folder(group_dir: Path, progress_callback: ProgressCB = None,
                         include_excluded: bool = False,
                         sim_threshold: float = 0.6, min_cluster_size: int = 2,
                         model: str = "hog", det_size: Tuple[int, int] = (640, 640)) -> Tuple[int, int, int]:
    group_dir = Path(group_dir)

    if include_excluded:
        commons = find_common_folders_recursive(group_dir)
        for i, c in enumerate(commons):
            if progress_callback:
                progress_callback(f"üìã –û–±—â–∏–µ: {c.name} ({i+1}/{len(commons)})", 5 + int(i / max(1, len(commons)) * 20))
            process_common_folder_at_level(c, progress_callback=progress_callback,
                                           sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                                           model=model)

    subdirs = [d for d in sorted(group_dir.iterdir()) if d.is_dir()]
    if not include_excluded:
        subdirs = [d for d in subdirs if all(ex not in d.name.lower() for ex in EXCLUDED_COMMON_NAMES)]

    total = len(subdirs)
    moved_all, copied_all = 0, 0
    next_cluster_id = 1  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å—á–µ—Ç—á–∏–∫ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –≤—Å–µ–π –≥—Ä—É–ø–ø—ã

    for i, sub in enumerate(subdirs):
        if progress_callback:
            progress_callback(f"üîç {sub.name}: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ({i+1}/{total})", 25 + int(i / max(1, total) * 60))
        data = build_plan_face_recognition(
            input_dir=sub,
            progress_callback=progress_callback,
            sim_threshold=sim_threshold,
            min_cluster_size=min_cluster_size,
            model=model,
        )
        m, c, next_cluster_id = distribute_to_folders(data, sub, cluster_start=next_cluster_id, progress_callback=progress_callback)
        moved_all += m
        copied_all += c

    return moved_all, copied_all, next_cluster_id


# ------------------------
# CLI-–æ–±–≤—è–∑–∫–∞
# ------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Face recognition + Faiss face clustering")
    parser.add_argument("input", type=str, help="–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏–ª–∏ –≥—Ä—É–ø–ø–∞ –ø–∞–ø–æ–∫")
    parser.add_argument("--group", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –≥—Ä—É–ø–ø—É –ø–æ–¥–ø–∞–ø–æ–∫")
    parser.add_argument("--include-common", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–∞–ø–∫–∏ '–æ–±—â–∏–µ' –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã")
    parser.add_argument("--sim", type=float, default=0.6, help="–ü–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ [0..1]")
    parser.add_argument("--minsz", type=int, default=2, help="–ú–∏–Ω. —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞")
    parser.add_argument("--model", type=str, default="hog", choices=["hog", "cnn"], help="–ú–æ–¥–µ–ª—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞")

    args = parser.parse_args()

    def cb(msg: str, p: int):
        print(f"[{p:3d}%] {msg}")

    if args.group:
        moved, copied, _ = process_group_folder(
            Path(args.input), progress_callback=cb,
            include_excluded=args.include_common,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            model=args.model,
        )
        print(f"DONE: moved={moved}, copied={copied}")
    else:
        data = build_plan_face_recognition(
            Path(args.input), progress_callback=cb,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            model=args.model,
        )
        m, c, _ = distribute_to_folders(data, Path(args.input), cluster_start=1, progress_callback=cb)
        print(f"DONE: moved={m}, copied={c}")
